"""
Image selection:
To begin, there are some images we need to exclude from the training data set.
    - Duplicate images are removed
        - Some images are identical
    - All 'new_whale' images are removed;
    - All whales with a single image are removed.

Matching whale examples:
Different whales examples are generated by computing a derangement of all pictures from the training set, subject to:
    - The image pairs must belong to different whales;
    - The pairs formed must be difficult for the model to distinguish.

Reference:
    # Siamese-Neural-Network-architecture
    - https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563

"""
import pandas as pd
from train import load_label_index_dict
from torch.utils.data import Dataset
import numpy as np
import cv2
import img_transform
from PIL import Image
import matplotlib.pyplot as plt


class SiameseTrainData(Dataset):
    '''
    Input parameter:
        transform_img
    '''

    def __init__(self, transform_img=None):
        super(SiameseTrainData, self).__init__()
        self.dataset, self.indexId = self.get_2img_data()
        self.names = self.dataset['Image']
        self.img_bbox_dict = self.load_bbox()
        self.transform = transform_img  # implement transform

    def __getitem__(self, img_index):
        '''

        '''
        if img_index % 2 == 0:
            return self.sample_same(img_index // 2)
        else:
            return self.sample_different((img_index - 1) // 2)

    def load_bbox(self):
        '''
        Load the bounding box to locate whale tails.
        '''
        # Image,x0,y0,x1,y1
        # print('loading bbox...')
        bbox = pd.read_csv('./input/bboxs.csv')
        Images = bbox['Image'].tolist()
        x0s = bbox['x0'].tolist()
        y0s = bbox['y0'].tolist()
        x1s = bbox['x1'].tolist()
        y1s = bbox['y1'].tolist()
        bbox_dict = {}
        for Single_Image, x0, y0, x1, y1 in zip(Images, x0s, y0s, x1s, y1s):
            bbox_dict[Single_Image] = [x0, y0, x1, y1]
        return bbox_dict

    def get_2img_data(self):
        '''
        Get the image from the whale owning more than 2 imgs and no new whale
        Return:
            1. Dataframe: Image, Id
            2. List: array
        '''

        data_train_no_new_whale_bigger_than_2 = pd.read_csv(
            "./input/train_no_new_bigger_than_2.csv")
        id_index_dict = load_label_index_dict()

        indexId_data_train_no_new_whale_bigger_than_2 = np.array([
            id_index_dict[label] for label in data_train_no_new_whale_bigger_than_2['Id']])
        return data_train_no_new_whale_bigger_than_2, indexId_data_train_no_new_whale_bigger_than_2

    def sample_same(self, idx):
        whale_id = self.indexId[idx]
        # return the list containing the all the index
        candidates = list(np.where(self.indexId == whale_id)[0])
        # remove the index one, so that we will not compare the same image
        candidates.remove(idx)

        if len(candidates) == 0:  # oops, there is only a single whale with this id in the dataset
            return self.sample_different(idx)

        # the shuffle operation is operated on the data
        np.random.shuffle(candidates)
        return self.construct_pair(self.names[idx], self.names[candidates[0]], 1)

    def sample_different(self, idx):
        whale_id = self.indexId[idx]
        candidates = list(np.where(self.indexId != whale_id)[0])
        np.random.shuffle(candidates)
        return self.construct_pair(self.names[idx], self.names[candidates[0]], 0)

    def construct_pair(self, im_name_a, im_name_b, class_flag):
        im_a = self.read_img(im_name_a)
        im_b = self.read_img(im_name_b)
        return [im_a, im_b], class_flag

    def read_img(self, img_name):
        im = cv2.imread(
            "../Humpback-Whale-Identification-1st--master/input/train/{}".format(img_name))
        try:
            x0, y0, x1, y1 = self.img_bbox_dict[img_name]
            im_bbox = im[int(y0):int(y1), int(x0):int(x1)
                         ]  # locate the whale tails
            im_processed = self.transform(im_bbox)
        except KeyError:
            im_processed = self.transform(im)
        return im_processed

    def __len__(self):
        return 2 * len(self.names)


if __name__ == '__main__':
    def transform_train_img(img):
        '''
        input: cv2.imread image. 
        return: transformed PIL from torchvision.transform

        '''
        # do a series of transform on images
        img_processed = img_transform.random_gaussian_noise(img, sigma=0.1)
        img_processed = img_transform.random_angle_rotate(img_processed)
        img_processed = img_transform.random_crop(img_processed)
        img = Image.fromarray(img_processed)

        transform_basic = img_transform.transforms_img()
        return transform_basic(img)

    dst = SiameseTrainData(transform_img=transform_train_img)
    img_pair, id_flag = dst[6]

    plt.imshow(np.transpose(img_pair[0], (1, 2, 0)))
    plt.show()
    plt.imshow(np.transpose(img_pair[1], (1, 2, 0)))
    plt.show()
    print(type(img_pair), len(img_pair), id_flag)
